# ============================================
# KNOWLEDGE SYSTEM ENVIRONMENT VARIABLES
# ============================================

# LLM Provider Configuration
# Options: ollama, gemini, openrouter
LLM_PROVIDER=gemini

# Gemini API Configuration (if using gemini)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=AIzaSyCJmOMb9Fc8p2G6RwM7xtMYIO61LB84uY8

# OpenRouter API Configuration (if using openrouter)
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Ollama Configuration (if using ollama)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3:0.6b

# Database Configuration
DB_PATH=data/knowledge_system.db

# Storage Configuration
DATA_DIR=data/data
CHAT_HISTORY_DIR=data/chat_history
CHROMA_DIR=data/chroma
HUGGINGFACE_CACHE=data/huggingface

# Security (Change in production!)
SECRET_KEY=your-secret-key-change-this-in-production
SESSION_DURATION_HOURS=24

# Admin Default Credentials (Change after first login!)
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123

# Application Configuration
DEBUG=False
LOG_LEVEL=INFO

# Performance Tuning (Token Optimization)
# Lower values = fewer tokens used = lower API costs
CHUNK_SIZE=600          # Document chunk size (reduced from 800)
CHUNK_OVERLAP=50        # Document chunk overlap (reduced from 100)
SIMILARITY_TOP_K=3      # Number of context chunks retrieved (reduced from 5)
NUM_QUERIES=2           # Number of query variations generated (reduced from 3)
TOP_K_RERANK=3          # Number of chunks after reranking (reduced from 4)
CHAT_TOKEN_LIMIT=6000   # Max tokens for chat memory (reduced from 12000)
MAX_TOKENS=1000         # Max tokens per response (reduced from 2000)
CHAT_HISTORY_LIMIT=4    # Number of recent Q&A pairs to keep in context

# Network Configuration (for docker)
ADMIN_PORT=7860
USER_PORT=7861
OLLAMA_PORT=11434
CHROMA_PORT=8000
